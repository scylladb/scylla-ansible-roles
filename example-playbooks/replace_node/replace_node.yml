---
# This play will make sure that the node being replaced is down and prevent it from trying to re-join
# the cluster by blocking its ip via iptables.
- name: Prepare nodes before replacement
  hosts: scylla
  vars_files:
    - vars/main.yml
  tasks:
    - name: Resolve a scylla_listen_address as a fact
      set_fact:
        listen_address: "{{ alive_nodes_listen_address }}"

    - name: Resolve scylla_broadcast_address as a fact
      set_fact:
        broadcast_address: "{{ alive_nodes_broadcast_address }}"

    - name: Stop scylla-server on the node being replaced
      block:
        - name: Disable Scylla service
          service:
            name: scylla-server
            enabled:  false
          become: true

        - name: Run nodetool drain
          async_task:
            shell: |
              nodetool drain
            alias: drain_scylla
            async: 60
            retries: 60
            delay: 1
          ignore_errors: true
          register: _drain_scylla_output

        - name: Stop Scylla service
          async_task:
            shell: |
              systemctl stop scylla-server
            alias: stop_scylla
            async: 5
            retries: 5
            delay: 1
          ignore_errors: true
          register: _stop_scylla_output
          become: true

        - name: Send SIGKILL to scylla
          shell: |
            pkill -9 scylla$
          ignore_errors: true
          become: true
      delegate_to: "{{ replaced_node }}"
      run_once: true
      when: alive_node_replace is defined and alive_node_replace|bool

    - name: Define temporary seed
      set_fact:
        temporary_seed: "{% if new_node == groups['scylla'][0] %}{{ groups['scylla'][1] }}{% else %}{{ groups['scylla'][0] }}{% endif %}"
      run_once: true

    - name: Check if CQL port is up on {{ replaced_node_broadcast_address }}
      wait_for:
        port: "{{ cql_port }}"
        host: "{{ replaced_node_broadcast_address }}"
        timeout: 60
      register: _wait_for_cql_port_output
      ignore_errors: true
      delegate_to: "{{ temporary_seed }}"
      run_once: true

    - name: Validate that the node being replaced is down
      fail:
        msg: "The node {{ replaced_node }} must be down in order to be replaced!"
      when: _wait_for_cql_port_output.failed|bool == false
      run_once: true

    - name: Check if the other nodes are UP
      wait_for:
        port: "{{ cql_port }}"
        host: "{{ listen_address }}"
        timeout: 60
      when: inventory_hostname != new_node

    - name: Block replaced node's broadcast_address to prevent it from trying to join the cluster again
      iptables:
        chain: INPUT
        source: "{{ replaced_node_broadcast_address }}"
        jump: DROP
      become: true

    # By doing this we make sure that the new node will have the same io_properties as the others
    - name: Save io_properties from the seed node
      block:
        - name: store /etc/scylla.d/io_properties.yaml
          shell: |
            cat /etc/scylla.d/io_properties.yaml
          register: _io_properties

        - set_fact:
            io_properties: "{{ _io_properties.stdout }}"
      delegate_to: "{{ temporary_seed }}"
      run_once: true


# This play will install Scylla in the new node.
# The same variables used when the node role was executed for the replaced node should also
# be passed to this playbook and will be used by this play.
- name: Install/Update Scylla in the new node
  hosts: "{{ new_node }}"
  vars_files:
    - vars/main.yml
  vars:
    firewall_enabled: true
  roles:
    - ansible-scylla-node


- name: Update scylla-monitoring
  hosts: scylla-monitor
  roles:
    - ansible-scylla-monitoring


# This play will set the ip/host_id of the replaced node in the scylla.yaml of the new node,
# start the new node, and then wait until the new node finishes joining the cluster. The same
# variables used when the node role was executed for the replaced node should also be passed
# to this playbook and will be used by this play.
- name: Start Scylla in the new node
  hosts: "{{ new_node }}"
  vars_files:
    - vars/main.yml
  become: true
  tasks:
    - name: Get current seeds
      shell: |
        grep '\- seeds:' /etc/scylla/scylla.yaml | awk '{ print $NF }'
      register: _current_seeds

    - name: Save current seeds list as a fact
      set_fact:
        original_seeds: "{{ _current_seeds.stdout }}"

    - name: Set temporary_seed as seed for the new node
      lineinfile:
        path: /etc/scylla/scylla.yaml
        regexp: '^(\s+) - seeds:'
        line: |
          \g<1> - seeds: {{ temporary_seed }}
        backrefs: yes

    - name: Check if replace_node_first_boot is available in the current Scylla version
      shell: |
        scylla --help | grep replace-node-first-boot
      register: _replace_node_first_boot_grep
      ignore_errors: true

    - name: Set replace_node_first_boot
      block:
        - name: Get the host id for all nodes
          uri:
            url: "http://{{ scylla_api_address }}:{{ scylla_api_port }}/storage_service/host_id"
            method: GET
          register: _host_ids
          until: _host_ids.status == 200
          retries: 5
          delay: 1
          delegate_to: "{{ temporary_seed }}"

        - set_fact:
            _replaced_node_host_id: "{{ item.value }}"
          when: item.key == replaced_node or item.key == replaced_node_broadcast_address
          loop: "{{ _host_ids.json }}"

        - name: Set replace_node_first_boot
          lineinfile:
            path: /etc/scylla/scylla.yaml
            regexp: '^(#\s*)?replace_node_first_boot:'
            line: "replace_node_first_boot: {{ _replaced_node_host_id }}"
            create: yes
      when: _replace_node_first_boot_grep.failed == false

    - name: Set replace_address_first_boot
      lineinfile:
        path: /etc/scylla/scylla.yaml
        regexp: '^(#\s*)?replace_address_first_boot:'
        line: "replace_address_first_boot: {{ replaced_node_broadcast_address }}"
        create: yes
      when: _replace_node_first_boot_grep.failed

    - name: Start Scylla
      service:
        name: scylla-server
        state: started

    - name: Wait for CQL port on {{ listen_address }}
      wait_for:
        port: "{{ cql_port }}"
        host: "{{ listen_address }}"
        timeout: "{{ new_node_bootstrap_wait_time_sec }}"

    - name: Wait for the added node to become healthy
      shell: |
        nodetool status|grep -E '^UN'|grep -w "{{ vars['ansible_'~scylla_nic].ipv4.address }}"| wc -l
      register: node_count
      until: node_count.stdout|int == 1
      retries: "{{ new_node_bootstrap_wait_time_sec|int }}"
      delay: 1
      delegate_to: "{{ item }}"
      loop: "{{ groups['scylla'] }}"

    - name: Remove the replace_node_first_boot record
      lineinfile:
        path: /etc/scylla/scylla.yaml
        regexp: '^replace_node_first_boot:'
        state: absent
      when: _replace_node_first_boot_grep.failed == false

    - name: Remove the replace_address_first_boot record
      lineinfile:
        path: /etc/scylla/scylla.yaml
        regexp: '^replace_address_first_boot:'
        state: absent
      when: _replace_node_first_boot_grep.failed

    - name: start and enable the Manager agent service
      service:
        name: scylla-manager-agent
        state: restarted
        enabled: yes

    - name: Restore seeds list
      lineinfile:
        path: /etc/scylla/scylla.yaml
        regexp: '^(\s+) - seeds:'
        line: |
          \g<1> - seeds: {{ original_seeds }}
        backrefs: yes

    - name: Check if RBNO is available in the current Scylla version
      shell: |
        scylla --help | grep enable-repair-based-node-ops
      register: _enable_rbno_grep
      ignore_errors: true

    - name: Check if RBNO was enabled for node replacement
      block:
        - command: cat /etc/scylla/scylla.yaml
          ignore_errors: true
          register: _scylla_yaml_out

        - set_fact:
            _scylla_yaml_map: "{{ _scylla_yaml_out.stdout | from_yaml }}"

        - set_fact:
            _rbno_enabled: "{{ _scylla_yaml_map.enable_repair_based_node_ops is not defined or _scylla_yaml_map.enable_repair_based_node_ops }}"
            _rbno_allowed_for_replace: "{{ _scylla_yaml_map.allowed_repair_based_node_ops is not defined or 'replace' in _scylla_yaml_map.allowed_repair_based_node_ops }}"
      when: _enable_rbno_grep.failed == false


# This play will repair the new node if RBNO was not used and skip_repair is not set to true
- name: Repair the new node, if necessary
  hosts: scylla-manager
  vars_files:
    - vars/main.yml
  tasks:
    - name: Skip this play if RBNO was used for the replacement or if skip_repair is true
      meta: end_play
      when: skip_repair|bool or (hostvars[new_node]['_enable_rbno_grep'].failed == false and hostvars[new_node]['_rbno_enabled'] and hostvars[new_node]['_rbno_allowed_for_replace'])

    - name: Get cluster id
      shell: |
        sctool status | grep 'Cluster: {{ scylla_cluster_name }} ' | awk '{print $3}' | tr -d '()'
      register: _cluster_id

    - fail:
        msg: "Unable to find cluster {{ scylla_cluster_name }} in scylla-manager"
      when: _cluster_id.stdout|length == 0

    - name: Repair the new node
      shell: |
        sctool repair --cluster "{{ _cluster_id.stdout }}" --host "{{ new_node }}" {{ extra_repair_params }}
      register: _repair_id

    - name: Wait for the repair to finish
      shell:
        sctool progress "{{ _repair_id.stdout }}" --cluster "{{ _cluster_id.stdout }}" | grep "Status:" | awk '{print $2}'
      register: _repair_status
      until: _repair_status.stdout != "RUNNING"
      retries: "{{ new_node_repair_timeout_seconds|int // 30 }}" # retries = new_node_repair_timeout_seconds / delay
      delay: 30

    - fail:
        msg: "Repair failed!"
      when: _repair_status.stdout != "DONE"
